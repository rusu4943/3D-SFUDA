{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ac5daf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/ruitongs/.conda/envs/UDA/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "import os\n",
    "from scipy.ndimage import rotate\n",
    "from  reorient_nii import reorient_1\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import SimpleITK as sitk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2b52438",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/ruitongs/.conda/envs/UDA/lib/python3.7/site-packages/nilearn/__init__.py:67: FutureWarning: Python 3.7 support is deprecated and will be removed in release 0.12 of Nilearn. Consider switching to Python 3.9 or 3.10.\n",
      "  _python_deprecation_warnings()\n"
     ]
    }
   ],
   "source": [
    "import nibabel as nib\n",
    "import nilearn.plotting as nlplt\n",
    "from nibabel.testing import data_path\n",
    "from scipy.ndimage import affine_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5090900",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'mr_train/'\n",
    "save_folder_path = 'mr_npy/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "099c7ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_label_value(image_data):\n",
    "    \n",
    "    image_data[image_data == 820] = 4 # AA  # small isolated\n",
    "    image_data[image_data == 500] = 3 # LV  # center \n",
    "    image_data[image_data == 421] = 2 # LA  # long tail # only 1 case has 421\n",
    "    image_data[image_data == 420] = 2 # LA  # long tail \n",
    "    image_data[image_data == 205] = 1 # Myo # blue semi-cicle close to red   \n",
    "\n",
    "    image_data[image_data == 550] = 0\n",
    "    image_data[image_data == 600] = 0\n",
    "    image_data[image_data == 850] = 0\n",
    "    \n",
    "    return image_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a2fd4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample(image_data):\n",
    "    \n",
    "    target_shape = [256, 256, 256]\n",
    "    \n",
    "    image_data = torch.from_numpy( image_data.copy() ).unsqueeze(0).unsqueeze(0) # torch.Size([1, 1, 512, 512, 84])\n",
    "    image_data = F.interpolate( image_data, target_shape, mode = \"nearest\").numpy()[0,0] # (342, 342, 63)\n",
    "    \n",
    "    return image_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d327f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_2(img, image_data):\n",
    "    \n",
    "    image_header = img.header\n",
    "    \n",
    "    target_shape = [int(image_data.shape[0] * image_header['pixdim'][1]), int(image_data.shape[1] * image_header['pixdim'][2]),\\\n",
    "                int(image_data.shape[2] * image_header['pixdim'][3])]\n",
    "    \n",
    "    \n",
    "    image_data = torch.from_numpy( image_data.copy() ).unsqueeze(0).unsqueeze(0) # torch.Size([1, 1, 512, 512, 84])\n",
    "    image_data = F.interpolate( image_data, target_shape, mode = \"nearest\").numpy()[0,0] # (342, 342, 63)\n",
    "    \n",
    "    return image_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b326bc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corp_base_on_min_max_label(image_data):\n",
    "\n",
    "    heart_indices = np.where(image_data != 0)\n",
    "    min_coords = np.min(heart_indices, axis=1)\n",
    "    max_coords = np.max(heart_indices, axis=1)\n",
    "    \n",
    "    cropped_volume = image_data[min_coords[0]:max_coords[0], min_coords[1]:max_coords[1], min_coords[2]:max_coords[2]]\n",
    "    #print('cropped_volume', cropped_volume.shape)\n",
    "    \n",
    "    return cropped_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15b59c3b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(137, 56, 274)\n",
      "[0. 1. 2. 3. 4.]\n",
      "__________________________\n",
      "(308, 65, 295)\n",
      "[0. 1. 2. 3. 4.]\n",
      "__________________________\n",
      "(123, 85, 215)\n",
      "[0. 1. 2. 3. 4.]\n",
      "__________________________\n",
      "(87, 90, 186)\n",
      "[0. 1. 2. 3. 4.]\n",
      "__________________________\n",
      "(123, 87, 137)\n",
      "[0. 1. 2. 3. 4.]\n",
      "__________________________\n",
      "(171, 75, 127)\n",
      "[0. 1. 2. 3. 4.]\n",
      "__________________________\n",
      "(147, 69, 141)\n",
      "[0. 1. 2. 3. 4.]\n",
      "__________________________\n",
      "(113, 123, 149)\n",
      "[0. 1. 2. 3. 4.]\n",
      "__________________________\n",
      "(140, 43, 354)\n",
      "[0. 1. 2. 3. 4.]\n",
      "__________________________\n",
      "(138, 90, 220)\n",
      "[0. 1. 2. 3. 4.]\n",
      "__________________________\n",
      "(146, 126, 136)\n",
      "[0. 1. 2. 3. 4.]\n",
      "__________________________\n",
      "(131, 62, 316)\n",
      "[0. 1. 2. 3. 4.]\n",
      "__________________________\n",
      "(137, 48, 333)\n",
      "[0. 1. 2. 3. 4.]\n",
      "__________________________\n",
      "(115, 52, 258)\n",
      "[0. 1. 2. 3. 4.]\n",
      "__________________________\n",
      "(159, 129, 187)\n",
      "[0. 1. 2. 3. 4.]\n",
      "__________________________\n",
      "(100, 78, 149)\n",
      "[0. 1. 2. 3. 4.]\n",
      "__________________________\n",
      "(112, 80, 180)\n",
      "[0. 1. 2. 3. 4.]\n",
      "__________________________\n",
      "(126, 113, 203)\n",
      "[0. 1. 2. 3. 4.]\n",
      "__________________________\n",
      "(107, 94, 148)\n",
      "[0. 1. 2. 3. 4.]\n",
      "__________________________\n",
      "(110, 82, 167)\n",
      "[0. 1. 2. 3. 4.]\n",
      "__________________________\n"
     ]
    }
   ],
   "source": [
    "for idx in range(1001, 1021):\n",
    "    filepath = os.path.join(folder_path + f'mr_train_{idx}_label.nii.gz')\n",
    "    img_0 = nib.load(filepath)\n",
    "    img = reorient_1(img_0)\n",
    "    image_data = img.get_fdata(dtype=np.float32)\n",
    "    image_data = resample_2(img_0, image_data)\n",
    "    #print(image_data.shape)\n",
    "    image_data = reset_label_value(image_data)\n",
    "    image_data = corp_base_on_min_max_label(image_data)\n",
    "    print(image_data.shape)\n",
    "    print(np.unique(image_data))\n",
    "    print('_'*26)\n",
    "    \n",
    "    np.save(f\"{save_folder_path}mr_train_{idx}_label.npy\", image_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3327970",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dbc824",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
