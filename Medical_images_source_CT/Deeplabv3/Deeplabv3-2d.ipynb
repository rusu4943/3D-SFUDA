{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83eb3e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/ruitongs/.conda/envs/UDA/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b8ba7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/ruitongs/.conda/envs/UDA/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "/home1/ruitongs/.conda/envs/UDA/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchvision.models.vgg16(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d79c505",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16_Backbone(nn.Module):\n",
    "    def __init__(self, dropout=None):\n",
    "        super(VGG16_Backbone, self).__init__()\n",
    "        original = torchvision.models.vgg16(pretrained=True)\n",
    "\n",
    "        layers = []\n",
    "        block_counter = 1\n",
    "        for idx, layer in enumerate(original.features.children()):\n",
    "            if isinstance(layer, nn.Conv2d):\n",
    "                if block_counter == 4:\n",
    "                    layer = nn.Conv2d(layer.in_channels, layer.out_channels, layer.kernel_size,\n",
    "                                      padding=2, dilation=2, bias=layer.bias is not None)\n",
    "                elif block_counter == 5:\n",
    "                    layer = nn.Conv2d(layer.in_channels, layer.out_channels, layer.kernel_size,\n",
    "                                      padding=4, dilation=4, bias=layer.bias is not None)\n",
    "\n",
    "            if not (isinstance(layer, nn.MaxPool2d) and (block_counter == 4 or block_counter == 5)):\n",
    "                    layers.append(layer)\n",
    "\n",
    "            if isinstance(layer, nn.MaxPool2d):\n",
    "                block_counter += 1\n",
    "\n",
    "        self.backbone = nn.Sequential(*layers)\n",
    "\n",
    "        if dropout is not None:\n",
    "            for idx, layer in enumerate(self.backbone.children()):\n",
    "                if isinstance(layer, nn.Conv2d):\n",
    "                    self.backbone[idx] = nn.Sequential(layer, nn.Dropout(dropout))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84e8edce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ASPPModule(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, dilation):\n",
    "        super(ASPPModule, self).__init__()\n",
    "        self.padding = dilation\n",
    "        self.kernel_size = 3\n",
    "        self.dilation = dilation\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=self.kernel_size, padding=0, dilation=dilation, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        padding = ((self.kernel_size - 1) * self.dilation) // 2\n",
    "        x = F.pad(x, (padding, padding, padding, padding))\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = F.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04bc8e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepLabV3(nn.Module):\n",
    "    def __init__(self, num_classes=5, backbone='vgg16', activation=None):\n",
    "        super(DeepLabV3, self).__init__()\n",
    "        assert backbone in ['vgg16']\n",
    "\n",
    "        if backbone == 'vgg16':\n",
    "            self.backbone = VGG16_Backbone()\n",
    "\n",
    "        self.aspp1 = nn.Sequential(\n",
    "            nn.Conv2d(512, 256, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.aspp_modules = nn.ModuleList([\n",
    "            ASPPModule(512, 256, dilation=12),\n",
    "            ASPPModule(512, 256, dilation=24),\n",
    "            ASPPModule(512, 256, dilation=36)\n",
    "        ])\n",
    "\n",
    "        self.global_pooling = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Conv2d(512, 256, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.concat = nn.Sequential(\n",
    "            nn.Conv2d(1280, 256, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "\n",
    "        self.project = nn.Sequential(\n",
    "            nn.Conv2d(256, 256, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.post_project = nn.Sequential(\n",
    "            nn.ZeroPad2d(1),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, num_classes, kernel_size=1)\n",
    "        )\n",
    "        \n",
    "\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, x):\n",
    "        img_size = (x.shape[2], x.shape[3])\n",
    "        \n",
    "        x = self.backbone(x)\n",
    "        x1 = self.aspp1(x)\n",
    "\n",
    "        aspp_outputs = [x1]\n",
    "        for aspp_module in self.aspp_modules:\n",
    "            aspp_outputs.append(aspp_module(x))\n",
    "\n",
    "        x5 = self.global_pooling(x) #x5: torch.Size([batch, 256, 1, 1])\n",
    "        x5 = nn.Upsample(size=x.size()[2:], mode='bilinear', align_corners=False)(x5) #x5: torch.Size([batch, 256, 64, 64])\n",
    "        aspp_outputs.append(x5)\n",
    "        \n",
    "        x = torch.cat(aspp_outputs, dim=1)\n",
    "        x = self.concat(x)\n",
    "        x = self.project(x)\n",
    "        x = self.post_project(x)\n",
    "        \n",
    "        x = nn.Upsample(size = img_size, mode='bilinear', align_corners=False)(x)\n",
    "        \n",
    "        if self.activation is not None:\n",
    "            x = self.activation(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5671f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabv3 = DeepLabV3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "007a5f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand((2, 3, 512, 512)) # bacth cannot be 1 because of BN2d/3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54908ad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.0890, -0.0890, -0.0890,  ...,  0.8531,  0.8531,  0.8531],\n",
       "          [-0.0890, -0.0890, -0.0890,  ...,  0.8531,  0.8531,  0.8531],\n",
       "          [-0.0890, -0.0890, -0.0890,  ...,  0.8531,  0.8531,  0.8531],\n",
       "          ...,\n",
       "          [ 0.9449,  0.9449,  0.9449,  ...,  0.8082,  0.8082,  0.8082],\n",
       "          [ 0.9449,  0.9449,  0.9449,  ...,  0.8082,  0.8082,  0.8082],\n",
       "          [ 0.9449,  0.9449,  0.9449,  ...,  0.8082,  0.8082,  0.8082]],\n",
       "\n",
       "         [[-0.0853, -0.0853, -0.0853,  ..., -0.0237, -0.0237, -0.0237],\n",
       "          [-0.0853, -0.0853, -0.0853,  ..., -0.0237, -0.0237, -0.0237],\n",
       "          [-0.0853, -0.0853, -0.0853,  ..., -0.0237, -0.0237, -0.0237],\n",
       "          ...,\n",
       "          [-0.2633, -0.2633, -0.2633,  ...,  0.2416,  0.2416,  0.2416],\n",
       "          [-0.2633, -0.2633, -0.2633,  ...,  0.2416,  0.2416,  0.2416],\n",
       "          [-0.2633, -0.2633, -0.2633,  ...,  0.2416,  0.2416,  0.2416]],\n",
       "\n",
       "         [[ 0.3049,  0.3049,  0.3049,  ...,  0.4436,  0.4436,  0.4436],\n",
       "          [ 0.3049,  0.3049,  0.3049,  ...,  0.4436,  0.4436,  0.4436],\n",
       "          [ 0.3049,  0.3049,  0.3049,  ...,  0.4436,  0.4436,  0.4436],\n",
       "          ...,\n",
       "          [ 0.3024,  0.3024,  0.3024,  ...,  0.2517,  0.2517,  0.2517],\n",
       "          [ 0.3024,  0.3024,  0.3024,  ...,  0.2517,  0.2517,  0.2517],\n",
       "          [ 0.3024,  0.3024,  0.3024,  ...,  0.2517,  0.2517,  0.2517]],\n",
       "\n",
       "         [[-0.5686, -0.5686, -0.5686,  ..., -0.2710, -0.2710, -0.2710],\n",
       "          [-0.5686, -0.5686, -0.5686,  ..., -0.2710, -0.2710, -0.2710],\n",
       "          [-0.5686, -0.5686, -0.5686,  ..., -0.2710, -0.2710, -0.2710],\n",
       "          ...,\n",
       "          [ 0.0627,  0.0627,  0.0627,  ...,  0.0688,  0.0688,  0.0688],\n",
       "          [ 0.0627,  0.0627,  0.0627,  ...,  0.0688,  0.0688,  0.0688],\n",
       "          [ 0.0627,  0.0627,  0.0627,  ...,  0.0688,  0.0688,  0.0688]],\n",
       "\n",
       "         [[-0.1467, -0.1467, -0.1467,  ...,  0.6600,  0.6600,  0.6600],\n",
       "          [-0.1467, -0.1467, -0.1467,  ...,  0.6600,  0.6600,  0.6600],\n",
       "          [-0.1467, -0.1467, -0.1467,  ...,  0.6600,  0.6600,  0.6600],\n",
       "          ...,\n",
       "          [ 0.1028,  0.1028,  0.1028,  ..., -0.0751, -0.0751, -0.0751],\n",
       "          [ 0.1028,  0.1028,  0.1028,  ..., -0.0751, -0.0751, -0.0751],\n",
       "          [ 0.1028,  0.1028,  0.1028,  ..., -0.0751, -0.0751, -0.0751]]],\n",
       "\n",
       "\n",
       "        [[[ 0.7896,  0.7896,  0.7896,  ...,  0.5442,  0.5442,  0.5442],\n",
       "          [ 0.7896,  0.7896,  0.7896,  ...,  0.5442,  0.5442,  0.5442],\n",
       "          [ 0.7896,  0.7896,  0.7896,  ...,  0.5442,  0.5442,  0.5442],\n",
       "          ...,\n",
       "          [-0.0185, -0.0185, -0.0185,  ...,  0.2353,  0.2353,  0.2353],\n",
       "          [-0.0185, -0.0185, -0.0185,  ...,  0.2353,  0.2353,  0.2353],\n",
       "          [-0.0185, -0.0185, -0.0185,  ...,  0.2353,  0.2353,  0.2353]],\n",
       "\n",
       "         [[ 0.0877,  0.0877,  0.0877,  ..., -0.0457, -0.0457, -0.0457],\n",
       "          [ 0.0877,  0.0877,  0.0877,  ..., -0.0457, -0.0457, -0.0457],\n",
       "          [ 0.0877,  0.0877,  0.0877,  ..., -0.0457, -0.0457, -0.0457],\n",
       "          ...,\n",
       "          [ 0.1483,  0.1483,  0.1483,  ...,  0.4953,  0.4953,  0.4953],\n",
       "          [ 0.1483,  0.1483,  0.1483,  ...,  0.4953,  0.4953,  0.4953],\n",
       "          [ 0.1483,  0.1483,  0.1483,  ...,  0.4953,  0.4953,  0.4953]],\n",
       "\n",
       "         [[-0.2541, -0.2541, -0.2541,  ..., -0.2181, -0.2181, -0.2181],\n",
       "          [-0.2541, -0.2541, -0.2541,  ..., -0.2181, -0.2181, -0.2181],\n",
       "          [-0.2541, -0.2541, -0.2541,  ..., -0.2181, -0.2181, -0.2181],\n",
       "          ...,\n",
       "          [-0.2747, -0.2747, -0.2747,  ...,  0.2904,  0.2904,  0.2904],\n",
       "          [-0.2747, -0.2747, -0.2747,  ...,  0.2904,  0.2904,  0.2904],\n",
       "          [-0.2747, -0.2747, -0.2747,  ...,  0.2904,  0.2904,  0.2904]],\n",
       "\n",
       "         [[ 0.2924,  0.2924,  0.2924,  ...,  0.0685,  0.0685,  0.0685],\n",
       "          [ 0.2924,  0.2924,  0.2924,  ...,  0.0685,  0.0685,  0.0685],\n",
       "          [ 0.2924,  0.2924,  0.2924,  ...,  0.0685,  0.0685,  0.0685],\n",
       "          ...,\n",
       "          [-0.3157, -0.3157, -0.3157,  ..., -0.5702, -0.5702, -0.5702],\n",
       "          [-0.3157, -0.3157, -0.3157,  ..., -0.5702, -0.5702, -0.5702],\n",
       "          [-0.3157, -0.3157, -0.3157,  ..., -0.5702, -0.5702, -0.5702]],\n",
       "\n",
       "         [[-0.2620, -0.2620, -0.2620,  ..., -0.1989, -0.1989, -0.1989],\n",
       "          [-0.2620, -0.2620, -0.2620,  ..., -0.1989, -0.1989, -0.1989],\n",
       "          [-0.2620, -0.2620, -0.2620,  ..., -0.1989, -0.1989, -0.1989],\n",
       "          ...,\n",
       "          [-0.1066, -0.1066, -0.1066,  ..., -0.4481, -0.4481, -0.4481],\n",
       "          [-0.1066, -0.1066, -0.1066,  ..., -0.4481, -0.4481, -0.4481],\n",
       "          [-0.1066, -0.1066, -0.1066,  ..., -0.4481, -0.4481, -0.4481]]]],\n",
       "       grad_fn=<UpsampleBilinear2DBackward1>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deeplabv3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ebd710",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
