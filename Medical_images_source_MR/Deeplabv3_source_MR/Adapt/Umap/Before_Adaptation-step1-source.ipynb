{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed03e3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import h5py\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from IPython.display import display as ipy_display, clear_output\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08533669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting path\n",
    "sys.path.append('/media/rs37890/d28c4aed-3c7e-4203-8590-f72f868ee829/rs37890/Medical_images_source_MR/Deeplabv3_source_MR/')\n",
    "deplabv3 = __import__('Deeplabv3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce14c0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting path\n",
    "import networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d196e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/media/rs37890/d28c4aed-3c7e-4203-8590-f72f868ee829/rs37890/Medical_images_source_MR/Deeplabv3_source_MR/Adapt/')\n",
    "dataset = __import__('Adaptation-step1-dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd79ccec",
   "metadata": {},
   "source": [
    "# parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fc9bf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 5\n",
    "batch_size = 1\n",
    "suffix = 'source'\n",
    "epoch = 20000\n",
    "dataset_name = 'abdomen'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a315fc",
   "metadata": {},
   "source": [
    "# CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c49fdc4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c2676b",
   "metadata": {},
   "source": [
    "# Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fe119a4-5f16-471d-86ab-5c6ea4eaf810",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/media/rs37890/d28c4aed-3c7e-4203-8590-f72f868ee829/rs37890/Medical_images_source_MR/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e45aa34",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_mr_train_dir =  root + \"data/data/h5py/\"\n",
    "source_mr_test_dir = root + \"data/data/h5py/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6b5aa20",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_ct_train_dir = root + \"data/data/h5py/\"\n",
    "target_ct_test_dir = root + \"data/data/h5py/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998759b6",
   "metadata": {},
   "source": [
    "# label_ids_abdomen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e8152a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_ids_abdomen = {\"ignore\": 0,\n",
    "    \"lv_myo\": 1,\n",
    "    \"la_blood\": 2,\n",
    "    \"lv_blood\": 3,\n",
    "    \"aa\": 4,\n",
    "}\n",
    "label_ids = label_ids_abdomen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b4e212",
   "metadata": {},
   "source": [
    "# Load model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e5567c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dpv3 = deplabv3.DeepLabV3(num_classes)\n",
    "classifier = networks.classifier(num_classes)\n",
    "\n",
    "dpv3 = dpv3.to(device)\n",
    "classifier = classifier.to(device)\n",
    "\n",
    "# parallel\n",
    "dpv3 = torch.nn.DataParallel(dpv3)\n",
    "classifier = torch.nn.DataParallel(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a300c6e-7dd6-4da5-ad2a-7d1433f16c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/media/rs37890/d28c4aed-3c7e-4203-8590-f72f868ee829/rs37890/Medical_images_source_MR/Deeplabv3_source_MR/record-data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da6072fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model weights\n"
     ]
    }
   ],
   "source": [
    "dpv3_checkpoint = torch.load( root + f'dpv3_weights_{epoch}.pth')\n",
    "classifier_checkpoint = torch.load( root + f'classifier_weights_{epoch}.pth')\n",
    "\n",
    "dpv3.load_state_dict(dpv3_checkpoint)\n",
    "classifier.load_state_dict(classifier_checkpoint)\n",
    "print(\"Loaded model weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4c56d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Combined_Model(nn.Module):\n",
    "    \n",
    "    def __init__(self, Unet, classifier):\n",
    "        super(Combined_Model, self).__init__()\n",
    "        \n",
    "        self.Unet = Unet\n",
    "        self.classifier = classifier\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        output1 = self.Unet(x)\n",
    "        output2 = self.classifier(output1)\n",
    "        \n",
    "        return output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6864610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the combined model\n",
    "combined = Combined_Model(dpv3, classifier)\n",
    "combined = combined.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f60bfdb",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "724fc04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = dataset.get_dataloader( target_ct_train_dir,  \n",
    "                                     target_ct_test_dir, \n",
    "                                     num_classes,\n",
    "                                     batch_size,\n",
    "                                     domain = 'source',\n",
    "                                   )\n",
    "\n",
    "# train_dataset = dataloader[\"train\"].dataset\n",
    "test_dataset = dataloader[\"test\"].dataset\n",
    "\n",
    "train_dataset = test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22b14d9",
   "metadata": {},
   "source": [
    "# learn gaussians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c55f2dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x, axis=-1, keepdims=True))\n",
    "    return e_x / np.sum(e_x, axis=-1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fdc7843d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_gaussians(dataset, z_model, sm_model, batch_size, label_ids, rho=.97, initial_means=None):    \n",
    "    \n",
    "    num_classes = len(label_ids)\n",
    "    \n",
    "    means = initial_means\n",
    "    if initial_means is None:\n",
    "        means = np.zeros((num_classes, num_classes)) \n",
    "        \n",
    "    covs = np.zeros((num_classes, num_classes, num_classes))\n",
    "    cnt = np.zeros(num_classes) \n",
    "    \n",
    "    N = len(dataset)\n",
    "    \n",
    "    i = 0\n",
    "\n",
    "    while i < N:\n",
    "        print(i,'/',N)\n",
    "        X, Y, sample_cnts = dataset[i]\n",
    "\n",
    "        if len(X) < 80:\n",
    "            batch_splits = [[X], [Y]]\n",
    "        # elif:\n",
    "        #     batch_splits = [X[:len(X)//2], X[len(X)//2:]], [Y[:len(Y)//2], Y[len(Y)//2:]]\n",
    "        else:\n",
    "            batch_splits = [ X[:len(X)//4], X[len(X)//4 : len(X)//2 ], X[ len(X)//2 : (3*len(X))//4 ], X[ (3*len(X))//4: ]], \\\n",
    "            [Y[ :len(Y)//4], Y[ len(Y)//4 : len(Y)//2 ], Y[ len(Y)//2 : (3*len(Y))//4], X[ (3*len(Y))//4:]]\n",
    "        \n",
    "        for data, y_true in zip(*batch_splits):\n",
    "            print(np.shape(data))\n",
    "            print(np.shape(y_true))\n",
    "            num_of_correct_prediction_each_classes = np.zeros(5, dtype=int)\n",
    "            \n",
    "            z_model.eval()\n",
    "            sm_model.eval()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                \n",
    "                input_data = torch.from_numpy(data).to(device)\n",
    "                input_data = input_data.float()\n",
    "                \n",
    "                zs = z_model(input_data).cpu() \n",
    "                zs = zs.permute(0, 2, 3, 4, 1)\n",
    "                zs = zs.reshape(-1, num_classes).detach().numpy()\n",
    "\n",
    "                y_hat = sm_model(input_data).softmax(dim = 1).cpu()\n",
    "                y_hat = y_hat.permute(0, 2, 3, 4, 1)\n",
    "                y_hat = y_hat.reshape(-1, num_classes).detach().numpy()\n",
    "            \n",
    "            vmax = np.max(y_hat, axis = 1) \n",
    "            y_hat = np.argmax(y_hat, axis = 1) \n",
    "            \n",
    "            y_t = y_true.ravel()\n",
    "\n",
    "            for label in label_ids:\n",
    "                c = label_ids[label]\n",
    "\n",
    "                # ind = (y_t == c) & (y_hat == c) & (vmax > rho)\n",
    "                ind = (y_t == c)  & (vmax > rho)\n",
    "                \n",
    "                if np.sum(ind) > 0:\n",
    "                    curr_data = zs[ind]\n",
    "                    num_of_correct_prediction_each_classes[c] = np.sum(ind)\n",
    "\n",
    "                    if initial_means is None:\n",
    "                        means[c] += np.sum(curr_data, axis=0)\n",
    "                        cnt[c] += np.sum(ind)\n",
    "\n",
    "                    else:\n",
    "                        \n",
    "                        sigma = np.dot(np.transpose(curr_data - means[c]), curr_data - means[c])\n",
    "                        covs[c] += sigma\n",
    "                        cnt[c] += np.sum(ind)\n",
    "        \n",
    "        i += 1\n",
    "\n",
    "        \n",
    "    # Normalize results\n",
    "    for i in range(num_classes):\n",
    "        if initial_means is None:\n",
    "            means[i] /= (cnt[i] + 1e-10)\n",
    "        covs[i] /= (cnt[i] - 1)\n",
    "        \n",
    "    assert np.isnan(means).any() == False\n",
    "    assert np.isnan(cnt).any() == False\n",
    "    \n",
    "    return means, covs, cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b41fb463",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 4\n",
      "(20, 1, 32, 32, 32)\n",
      "(20, 32, 32, 32)\n",
      "(20, 1, 32, 32, 32)\n",
      "(20, 32, 32, 32)\n",
      "(20, 1, 32, 32, 32)\n",
      "(20, 32, 32, 32)\n",
      "(20, 1, 32, 32, 32)\n",
      "(20, 1, 32, 32, 32)\n",
      "1 / 4\n",
      "(72, 1, 32, 32, 32)\n",
      "(72, 32, 32, 32)\n",
      "2 / 4\n",
      "(25, 1, 32, 32, 32)\n",
      "(25, 32, 32, 32)\n",
      "(25, 1, 32, 32, 32)\n",
      "(25, 32, 32, 32)\n",
      "(25, 1, 32, 32, 32)\n",
      "(25, 32, 32, 32)\n",
      "(25, 1, 32, 32, 32)\n",
      "(25, 1, 32, 32, 32)\n",
      "3 / 4\n",
      "(72, 1, 32, 32, 32)\n",
      "(72, 32, 32, 32)\n",
      "computed means in 5.770476341247559\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "means, _ , ct = learn_gaussians(train_dataset, dpv3, combined, batch_size, label_ids, rho=0.97, initial_means=None)\n",
    "\n",
    "print(\"computed means in\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6eb57dce-6734-43d0-9a8f-dced641f86cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 4\n",
      "(20, 1, 32, 32, 32)\n",
      "(20, 32, 32, 32)\n",
      "(20, 1, 32, 32, 32)\n",
      "(20, 32, 32, 32)\n",
      "(20, 1, 32, 32, 32)\n",
      "(20, 32, 32, 32)\n",
      "(20, 1, 32, 32, 32)\n",
      "(20, 1, 32, 32, 32)\n",
      "1 / 4\n",
      "(72, 1, 32, 32, 32)\n",
      "(72, 32, 32, 32)\n",
      "2 / 4\n",
      "(25, 1, 32, 32, 32)\n",
      "(25, 32, 32, 32)\n",
      "(25, 1, 32, 32, 32)\n",
      "(25, 32, 32, 32)\n",
      "(25, 1, 32, 32, 32)\n",
      "(25, 32, 32, 32)\n",
      "(25, 1, 32, 32, 32)\n",
      "(25, 1, 32, 32, 32)\n",
      "3 / 4\n",
      "(72, 1, 32, 32, 32)\n",
      "(72, 32, 32, 32)\n",
      "finished training gaussians in 3.412978410720825\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "means, covs, ct = learn_gaussians(train_dataset, dpv3, combined, batch_size, label_ids, rho=0.97, initial_means=means)\n",
    "\n",
    "print(\"finished training gaussians in\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f9f54b5-92e3-466f-a47b-5f0850f36a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"./extras/means_\" + dataset_name + \"_\" + suffix + \".npy\", means)\n",
    "np.save(\"./extras/covs_\" + dataset_name + \"_\" + suffix + \".npy\", covs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
