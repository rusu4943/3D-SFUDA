{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbcca3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nas/home/ruitongs/.conda/envs/UDA/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import h5py\n",
    "import time\n",
    "import tempfile\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display as ipy_display, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9172c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting path\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b8fc375",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_3D = __import__('3D-Unet-4')\n",
    "import networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d41b65cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e88a619",
   "metadata": {},
   "source": [
    "# parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cc3ea77",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 5\n",
    "batch_size = 1\n",
    "suffix = 'run4'\n",
    "\n",
    "dataset_name = 'abdomen'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219b6862",
   "metadata": {},
   "source": [
    "# CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a664850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109b6635",
   "metadata": {},
   "source": [
    "# Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8189c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_mr_train_dir = \"../../data2/preprocessed_data/\"\n",
    "source_mr_test_dir = \"../../data2/preprocessed_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "320ed641",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_ct_train_dir = \"../../data2/preprocessed_data/\"\n",
    "target_ct_test_dir = \"../../data2/preprocessed_data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61aca8e",
   "metadata": {},
   "source": [
    "# label_ids_abdomen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ad6a7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_ids_abdomen = {\"ignore\": 0,\n",
    "    \"liver\": 1,\n",
    "    \"right_kidney\": 2,\n",
    "    \"left_kidney\": 3,\n",
    "    \"spleen\": 4,\n",
    "}\n",
    "\n",
    "label_ids = label_ids_abdomen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6a5836",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "516bd3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_batch(dataset, batch_size=20, seed=None):\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    data_dir = dataset.data_dir\n",
    "    num_samples = len(dataset)\n",
    "    sample_indices = np.random.choice(num_samples, batch_size, replace=False) # replace=True allow repeat\n",
    "\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for idx in sample_indices:\n",
    "        \n",
    "        data_vol, label_vol = dataset[idx]\n",
    "        \n",
    "        images.append(data_vol)\n",
    "        labels.append(label_vol)\n",
    "\n",
    "    images = torch.stack(images)\n",
    "    labels = torch.stack(labels)\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5bd51c",
   "metadata": {},
   "source": [
    "#  sliding_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c7e46ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(input_volume, window_size=(32, 256, 256), stride=(16, 128, 128)):\n",
    "    \n",
    "    z_max = input_volume.shape[0] - window_size[0] + 1 # z_max = 269\n",
    "    y_range = range(0, input_volume.shape[1] - window_size[1] + 1, stride[1]) # 0, 128, 256\n",
    "    x_range = range(0, input_volume.shape[2] - window_size[2] + 1, stride[2]) # 0, 128, 256\n",
    "\n",
    "    windows = []\n",
    "\n",
    "    for y in y_range:\n",
    "        for x in x_range:\n",
    "            # Loop through the z slices with stride\n",
    "            # z_range: 0, 16, 32, 48, 64, 80, 96, 112, 128, 144, 160, 176, 192, 208, 224, 240, 256\n",
    "            for z in range(0, z_max, stride[0]):\n",
    "                window = input_volume[z:z+window_size[0], y:y+window_size[1], x:x+window_size[2]]\n",
    "                windows.append(window)\n",
    "\n",
    "            # Add an additional window for the remaining depth\n",
    "            z_remaining = input_volume.shape[0] - window_size[0] # z_remaining = 78 - 32 = 46\n",
    "            window = input_volume[z_remaining:, y:y+window_size[1], x:x+window_size[2]]\n",
    "            windows.append(window)\n",
    "\n",
    "    return windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db64dccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_windows(window_outputs, input_volume_shape, window_size=(32, 256, 256), stride=(16, 128, 128)):\n",
    "    num_classes = window_outputs[0].shape[1] # 5\n",
    "    combined_prob = torch.zeros((num_classes,) + input_volume_shape).to(device)\n",
    "    count_matrix = torch.zeros(input_volume_shape).to(device)\n",
    "\n",
    "    z_max = input_volume_shape[0] - window_size[0] + 1\n",
    "    y_range = range(0, input_volume_shape[1] - window_size[1] + 1, stride[1])\n",
    "    x_range = range(0, input_volume_shape[2] - window_size[2] + 1, stride[2])\n",
    "\n",
    "    idx = 0\n",
    "\n",
    "    for y in y_range:\n",
    "        for x in x_range:\n",
    "            # Loop through the z slices with stride\n",
    "            for z in range(0, z_max, stride[0]):\n",
    "                output = window_outputs[idx].squeeze() # output.cpu().numpy().shape: (5, 32, 256, 256)\n",
    "                combined_prob[:, z:z+window_size[0], y:y+window_size[1], x:x+window_size[2]] += output\n",
    "                count_matrix[z:z+window_size[0], y:y+window_size[1], x:x+window_size[2]] += 1\n",
    "                idx += 1\n",
    "\n",
    "            # Add an additional window for the remaining depth\n",
    "            z_remaining = input_volume_shape[0] - window_size[0]\n",
    "            output = window_outputs[idx].squeeze()\n",
    "            combined_prob[:, z_remaining:, y:y+window_size[1], x:x+window_size[2]] += output\n",
    "            count_matrix[z_remaining:, y:y+window_size[1], x:x+window_size[2]] += 1\n",
    "            idx += 1\n",
    "\n",
    "    # Normalize the class probabilities\n",
    "    combined_prob /= count_matrix\n",
    "\n",
    "    # Take the argmax of the accumulated probabilities\n",
    "    combined_output = torch.argmax(combined_prob, dim=0)\n",
    "\n",
    "    return combined_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df54b78",
   "metadata": {},
   "source": [
    "# compute_miou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d026fa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_miou(images, labels, Unet, classifier, label_ids, id_to_ignore=0):\n",
    "    N = len(images)\n",
    "\n",
    "    intersection = dict()\n",
    "    union = dict()\n",
    "    for label in label_ids:\n",
    "        intersection[label] = union[label] = 0\n",
    "    \n",
    "    Unet.eval()\n",
    "    classifier.eval()\n",
    "    \n",
    "    for i in range(N):\n",
    "        X = images[i].unsqueeze(0).to(device) # (1,3,256,256)\n",
    "        y_true = labels[i].view(-1).cpu().numpy()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            myans1 = Unet(X)\n",
    "            myans2 = classifier(myans1) # output: [1, 5, 256, 256]\n",
    "\n",
    "            # Apply softmax to the output logits\n",
    "            myans2_softmax = F.softmax(myans2, dim=1) # out size is: torch.Size([1, 5, 256, 256])\n",
    "\n",
    "            # Get class predictions by selecting the class with the highest probability\n",
    "            myans2_pred = torch.argmax(myans2_softmax, dim=1) # out size is: torch.Size([1, 256, 256])\n",
    "            \n",
    "            y_hat = myans2_pred.view(-1).cpu().numpy()\n",
    "\n",
    "        for label in label_ids:\n",
    "            if label_ids[label] == id_to_ignore:\n",
    "                continue\n",
    "\n",
    "            curr_id = label_ids[label]\n",
    "\n",
    "            idx_gt = y_true == curr_id\n",
    "            idx_hat = y_hat == curr_id\n",
    "\n",
    "            intersection[label] += np.sum(idx_gt & idx_hat)\n",
    "            union[label] += np.sum(idx_gt | idx_hat)\n",
    "\n",
    "    mIoU = []\n",
    "    res = dict()\n",
    "    for label in label_ids:\n",
    "        if label_ids[label] == id_to_ignore:\n",
    "            continue\n",
    "\n",
    "        if union[label] != 0:\n",
    "            res[label] = intersection[label] / union[label]\n",
    "        else:\n",
    "            res[label] = np.float64(0)\n",
    "\n",
    "        mIoU.append(res[label])\n",
    "    \n",
    "    return res, np.mean(mIoU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918f1fea",
   "metadata": {},
   "source": [
    "# Combined model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3319ea46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Combined_Model(nn.Module):\n",
    "    \n",
    "    def __init__(self, Unet, classifier):\n",
    "        super(Combined_Model, self).__init__()\n",
    "        \n",
    "        self.Unet = Unet\n",
    "        self.classifier = classifier\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        output1 = self.Unet(x)\n",
    "        output2 = self.classifier(output1)\n",
    "        \n",
    "        return output2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a303273d",
   "metadata": {},
   "source": [
    "# Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12c6b55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = dataset.get_dataloader( target_ct_train_dir,  target_ct_test_dir, num_classes, batch_size,  domain = 'target' )\n",
    "\n",
    "train_dataset = dataloader[\"train\"].dataset\n",
    "test_dataset = dataloader[\"test\"].dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f203058d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Unet = unet_3D.UNet(1, num_classes, 16)\n",
    "classifier = networks.Classifier(num_classes)\n",
    "\n",
    "Unet = Unet.to(device)\n",
    "classifier = classifier.to(device)\n",
    "\n",
    "# Create the combined model\n",
    "#combined = Combined_Model(Unet, Classifier)\n",
    "#combined = combined.to(device)\n",
    "\n",
    "# parallel\n",
    "#Unet = torch.nn.DataParallel(Unet, device_ids=[0, 1, 2, 3])\n",
    "#Classifier = torch.nn.DataParallel(Classifier, device_ids=[0, 1, 2, 3])\n",
    "\n",
    "Unet = torch.nn.DataParallel(Unet)\n",
    "classifier = torch.nn.DataParallel(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac00b49c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model weights\n"
     ]
    }
   ],
   "source": [
    "Unet_checkpoint = torch.load('../record-data/' + 'Unet_weights_' + suffix  + '.pth')\n",
    "classifier_checkpoint = torch.load('../record-data/' + 'classifier_weights_' + suffix + '.pth')\n",
    "\n",
    "Unet.load_state_dict(Unet_checkpoint)\n",
    "classifier.load_state_dict(classifier_checkpoint)\n",
    "print(\"Loaded model weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df57b02",
   "metadata": {},
   "source": [
    "# Show results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "107b7856",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_output = []\n",
    "\n",
    "for img_idx in range(len(test_dataset)): # 0, 1, 2, 3\n",
    "    \n",
    "    data_vol, label_vol = test_dataset[img_idx] # data_vol: torch.Size([1, 60, 512, 512])\n",
    "    data_vol = data_vol.to(device)\n",
    "    label_vol = label_vol.to(device)\n",
    "    \n",
    "    data_vol = torch.squeeze(data_vol, 0) # data_vol:  torch.Size([60, 512, 512])\n",
    "    windows = sliding_window(data_vol) # slice 3D image based on window size and stride\n",
    "    \n",
    "    \n",
    "    \n",
    "    window_outputs = []\n",
    "    \n",
    "    Unet.eval()\n",
    "    classifier.eval() \n",
    "    with torch.no_grad():\n",
    "        for window in windows:\n",
    "            window = window.unsqueeze(0)  # Add a channel dimension: torch.Size([1, 32, 256, 256])\n",
    "            window = torch.unsqueeze(window, 0)  # Add a batch dimension: torch.Size([1, 1, 32, 256, 256])\n",
    "            \n",
    "            # inference\n",
    "            output = Unet(window)\n",
    "            output = classifier(output) # torch.Size([1, 5, 32, 256, 256])\n",
    "            \n",
    "            # collect outputs\n",
    "            window_outputs.append(output)  # len(window_outputs) = 27\n",
    "            # window_outputs[0].cpu().numpy().shape： (1, 5, 32, 256, 256)\n",
    "\n",
    "    combined_output = combine_windows(window_outputs, data_vol.size())\n",
    "    test_output.append(combined_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1e4c86",
   "metadata": {},
   "source": [
    "# evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8bd7c2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_arrays = [tensor.cpu().numpy() for tensor in test_output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b621ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63, 512, 512)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_arrays[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0666c662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75, 512, 512)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_arrays[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3539c6e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 512, 512)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_arrays[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ba4431d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 512, 512)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_arrays[3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "88c35487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63, 512, 512)\n",
      "(63, 512, 512)\n",
      "(75, 512, 512)\n",
      "(75, 512, 512)\n",
      "(50, 512, 512)\n",
      "(50, 512, 512)\n",
      "(51, 512, 512)\n",
      "(51, 512, 512)\n",
      "(61, 512, 512)\n",
      "(61, 512, 512)\n",
      "(56, 512, 512)\n",
      "(56, 512, 512)\n"
     ]
    }
   ],
   "source": [
    "id_to_ignore = 0\n",
    "intersection = dict()\n",
    "total = dict()\n",
    "for label in label_ids:\n",
    "    intersection[label] = total[label] = 0\n",
    "\n",
    "\n",
    "for img_idx in range(len(test_dataset)): # 0, 1, 2, 3\n",
    "    \n",
    "    _, y_true = test_dataset[img_idx] # data_vol: torch.Size([1, 60, 512, 512])\n",
    "    \n",
    "    y_hat = numpy_arrays[img_idx]\n",
    "    y_true = y_true.cpu().numpy() \n",
    "    \n",
    "    print(y_hat.shape)\n",
    "    print(y_true.shape)\n",
    "    \n",
    "    for label in label_ids:\n",
    "        if label_ids[label] == id_to_ignore:\n",
    "            continue\n",
    "\n",
    "        curr_id = label_ids[label]\n",
    "\n",
    "        idx_gt = y_true == curr_id\n",
    "        idx_hat = y_hat == curr_id\n",
    "\n",
    "        intersection[label] += 2 * np.sum(idx_gt & idx_hat)\n",
    "        total[label] += np.sum(idx_gt) + np.sum(idx_hat)\n",
    "        \n",
    "    dice = []\n",
    "    res = dict()\n",
    "    for label in label_ids:\n",
    "        if label_ids[label] == id_to_ignore:\n",
    "            continue\n",
    "            \n",
    "        if total[label] != 0:\n",
    "            res[label] = intersection[label] / total[label]\n",
    "        else:\n",
    "            print('total is zero')\n",
    "            res[label] = np.float64(0)\n",
    "\n",
    "        dice.append(res[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "619ea79b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.018396567250762587"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(dice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b15c658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "liver 0.0\n",
      "right_kidney 0.0\n",
      "left_kidney 0.03390754831696667\n",
      "spleen 0.03967872068608367\n"
     ]
    }
   ],
   "source": [
    "for k in res:\n",
    "    print(k, res[k])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
